{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Competition: ASHRAE - Great Energy Predictor III"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "São feitos investimentos significativos para melhorar a eficiência de construções e reduzir custos e emissões. A questão é: as melhorias estão funcionando? Com o pagamento por desempenho, o proprietário do edifício paga com base na diferença entre o consumo real de energia e o que eles teriam usado sem nenhuma reforma. Os últimos valores têm que vir de um modelo. Os métodos atuais de estimativa são fragmentados e não escalam bem. Alguns assumem um tipo específico de medidor ou não trabalham com diferentes tipos de construção.\n",
    "\n",
    "Nesta competição, terão de ser desenvolvidos modelos precisos do uso de energia de edifícios medidos nas seguintes áreas: medidores de água resfriada, elétrica, água quente e vapor. Os dados são provenientes de mais de 1.000 edifícios em um período de três anos (62 milhões de linhas). Com melhores estimativas desses investimentos em economia de energia, os investidores em larga escala e as instituições financeiras estarão mais inclinadas a investir nessa área para permitir o progresso de edificações eficientes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_squared_log_error\n",
    "from math import sqrt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import random, datetime, math, gc\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "\n",
    "SEED = 99\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### A parte de análise exploratória dos dados, e de minificação e tratamento dos dados foram realizados em outros notebooks que serão postados posteriormente durante o desenvolvimento deste projeto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foram fornecidos 5 arquivos pela competição, os arquivos de treino e teste com Id’s das construções, quando as medições foram feitas e informações sobre o tipo de energia que é consumida. Os arquivos de dados climáticos para os períodos das medições de treino e teste e as informações sobre as construções. Fiz o tratamento dos dados em um notebook anterior a este, onde realizei a minificação dos dados e a junção de todos os dados em dados de treino (aproximadamente 20 milhões de linhas) e teste (aproximadamente 42 milhões de linhas). Esse notebook forneceu como saída os dois arquivos .pkl que usarei neste notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (20216100, 16) , Test (41697600, 16)\n"
     ]
    }
   ],
   "source": [
    "dftrain = pd.read_pickle('train.pkl')\n",
    "dftest = pd.read_pickle('test.pkl')\n",
    "print ('Train: %s , Test %s' % (dftrain.shape, dftest.shape) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>meter</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>meter_reading</th>\n",
       "      <th>site_id</th>\n",
       "      <th>primary_use</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>year_built</th>\n",
       "      <th>floor_count</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>cloud_coverage</th>\n",
       "      <th>dew_temperature</th>\n",
       "      <th>precip_depth_1_hr</th>\n",
       "      <th>sea_level_pressure</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>wind_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>7432</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1019.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>2720</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1019.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>5376</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1019.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>23685</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1019.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>116607</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1019.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   building_id  meter            timestamp  meter_reading  site_id  \\\n",
       "0            0      0  2016-01-01 00:00:00            0.0        0   \n",
       "1            1      0  2016-01-01 00:00:00            0.0        0   \n",
       "2            2      0  2016-01-01 00:00:00            0.0        0   \n",
       "3            3      0  2016-01-01 00:00:00            0.0        0   \n",
       "4            4      0  2016-01-01 00:00:00            0.0        0   \n",
       "\n",
       "  primary_use  square_feet  year_built  floor_count  air_temperature  \\\n",
       "0   Education         7432      2008.0          NaN             25.0   \n",
       "1   Education         2720      2004.0          NaN             25.0   \n",
       "2   Education         5376      1991.0          NaN             25.0   \n",
       "3   Education        23685      2002.0          NaN             25.0   \n",
       "4   Education       116607      1975.0          NaN             25.0   \n",
       "\n",
       "   cloud_coverage  dew_temperature  precip_depth_1_hr  sea_level_pressure  \\\n",
       "0             6.0             20.0                NaN              1019.7   \n",
       "1             6.0             20.0                NaN              1019.7   \n",
       "2             6.0             20.0                NaN              1019.7   \n",
       "3             6.0             20.0                NaN              1019.7   \n",
       "4             6.0             20.0                NaN              1019.7   \n",
       "\n",
       "   wind_direction  wind_speed  \n",
       "0             0.0         0.0  \n",
       "1             0.0         0.0  \n",
       "2             0.0         0.0  \n",
       "3             0.0         0.0  \n",
       "4             0.0         0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizo a junção dos dados de treino e teste para ser realizada a feature engineering em todos os dados juntos. Apesar deste método não ser viável em produção em muitos dos casos, no âmbito da competição é eficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape : (61913700, 17)\n"
     ]
    }
   ],
   "source": [
    "dffe = pd.concat([dftrain,dftest], axis =0, ignore_index=True, sort=False)\n",
    "print('Shape :',dffe.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preencho os valores nulos com 0 e -999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dffe['floor_count'] = dffe['floor_count'].fillna(0).astype(np.int8)\n",
    "dffe['year_built'] = dffe['year_built'].fillna(-999).astype(np.int16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta fase desenvolvi features referentes ao tempo para contribuir com a detecção de sazonalidade pelo modelo. Também foi adicionado um dataset intrínseco do Pandas referente a feriados americanos que podem contribuir com o consumo de energia das edificações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dffe['timestamp'] = pd.to_datetime(dffe['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_range = pd.date_range(start='2015-12-31', end='2019-01-01')\n",
    "us_holidays = calendar().holidays(start=dates_range.min(), end=dates_range.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dffe['DT_MO'] = dffe['timestamp'].dt.month.astype(np.int8)\n",
    "dffe['DT_WY'] = dffe['timestamp'].dt.weekofyear.astype(np.int8)\n",
    "dffe['DT_DY'] = dffe['timestamp'].dt.dayofyear.astype(np.int16)\n",
    "dffe['is_holiday'] = (dffe['timestamp'].dt.date.astype('datetime64').isin(us_holidays)).astype(np.int8)\n",
    "dffe['DT_H'] = dffe['timestamp'].dt.hour.astype(np.int8)\n",
    "dffe['DT_day_week'] = dffe['timestamp'].dt.dayofweek.astype(np.int8)\n",
    "dffe['DT_day_month'] = dffe['timestamp'].dt.day.astype(np.int8)\n",
    "dffe['DT_week_month'] = dffe['timestamp'].dt.day/7\n",
    "dffe['DT_week_month'] = dffe['DT_week_month'].apply(lambda x: math.ceil(x)).astype(np.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fiz o logaritmo da variável target, para ter uma distribuição mais próxima da normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dffe['meter_reading'] = np.log1p(dffe['meter_reading'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deletei as colunas que não serão utilizadas pelo modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dffe.drop(['timestamp','row_id'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformei as colunas que são categóricas no tipo “category” para o Lgbm lidar melhor com estas colunas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = ['DT_MO','DT_WY','DT_DY','DT_H','DT_day_week','DT_day_month','DT_week_month','meter','primary_use','site_id','building_id']\n",
    "for col in category :\n",
    "    dffe[col] = dffe[col].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A validação foi feita replicando da melhor maneira possível a situação encontrada na competição. Na competição há 1 ano e meio de dados de treino e 1 ano e meio de dados de teste. Então eu utilizei uma técnica de holdout que funciona melhor para time series, dividi os dados de treino que estão organizados pelo tempo na metade, e usei a primeira parte para treino e a segunda para validação. As previsões foram realizadas nestes dados de treino através do metodo de validação cruzada KFold e os resultados comparados com os dados de validação do holdout. Neste setup são feitos os testes de feature engineering adicionando uma feature por vez e observando se a métrica de avaliação do modelo RMSLE melhora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape treino: (10108050, 23) | Shape teste: (10108050, 23)\n"
     ]
    }
   ],
   "source": [
    "df_val_train = dffe[:int(dftrain.shape[0]*0.5)]\n",
    "df_val_test  = dffe[int(dftrain.shape[0]*0.5):dftrain.shape[0]]\n",
    "print('Shape treino: {:} | Shape teste: {:}'.format(df_val_train.shape, df_val_test.shape))\n",
    "X_val_train = df_val_train.drop(['meter_reading'], axis = 1)\n",
    "y_val_train  = df_val_train.meter_reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "                    'objective':'regression',\n",
    "                    'metric':'rmse',\n",
    "                    'n_jobs':-1,\n",
    "                    'learning_rate':0.25,\n",
    "                    'num_leaves': 40,\n",
    "                    'max_depth':-1,\n",
    "                    'subsample':0.85,\n",
    "                    'n_estimators':100,\n",
    "                    'seed': SEED,\n",
    "                    'early_stopping_rounds':100, \n",
    "                } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[25]\ttraining's rmse: 0.879328\tvalid_1's rmse: 0.882023\n",
      "[50]\ttraining's rmse: 0.783415\tvalid_1's rmse: 0.787898\n",
      "[75]\ttraining's rmse: 0.750123\tvalid_1's rmse: 0.756113\n",
      "[100]\ttraining's rmse: 0.727066\tvalid_1's rmse: 0.734433\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's rmse: 0.727066\tvalid_1's rmse: 0.734433\n",
      "Wall time: 53.6 s\n",
      "Wall time: 36.1 s\n",
      "\n",
      "Fold: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[25]\ttraining's rmse: 0.879265\tvalid_1's rmse: 0.880188\n",
      "[50]\ttraining's rmse: 0.783023\tvalid_1's rmse: 0.785983\n",
      "[75]\ttraining's rmse: 0.745779\tvalid_1's rmse: 0.750223\n",
      "[100]\ttraining's rmse: 0.721741\tvalid_1's rmse: 0.727372\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's rmse: 0.721741\tvalid_1's rmse: 0.727372\n",
      "Wall time: 50.4 s\n",
      "Wall time: 39.6 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "K = 2\n",
    "folds = KFold(K, shuffle=True, random_state = SEED)\n",
    "finalpred_validation = np.zeros(df_val_train.shape[0])\n",
    "for fold , (train_index,test_index) in enumerate(folds.split(X_val_train, y_val_train)):\n",
    "    print('Fold:',fold+1)\n",
    "          \n",
    "    X_traincv, X_testcv = X_val_train.iloc[train_index], X_val_train.iloc[test_index]\n",
    "    y_traincv, y_testcv = y_val_train.iloc[train_index], y_val_train.iloc[test_index]\n",
    "    \n",
    "    train_data = lgb.Dataset(X_traincv, y_traincv)\n",
    "    val_data   = lgb.Dataset(X_testcv, y_testcv)\n",
    "    \n",
    "    %time LGBM = lgb.train(lgb_params, train_data, valid_sets=[train_data,val_data], verbose_eval=25)\n",
    "    %time finalpred_validation += np.expm1(LGBM.predict(df_val_test.drop(['meter_reading'], axis = 1)))\n",
    "    print()\n",
    "    \n",
    "finalpred_validation /= K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared logarithm error: 3.03\n"
     ]
    }
   ],
   "source": [
    "finalpred_validation = np.where((finalpred_validation < 0), 0, finalpred_validation)\n",
    "print(\"Root mean squared logarithm error: %.2f\"\n",
    "      % np.sqrt(mean_squared_log_error(df_val_test.meter_reading, finalpred_validation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_val_train, df_val_test, X_val_train, y_val_train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A modelagem foi realizada em um setup de validação cruzada KFold com 5 folds. O modelo faz a validação com a fold que ficou de fora em cada iteração, usando esta mesma fold para parar o treino em caso de não haver mais melhora da métrica de avaliação. Inicialmente separo de volta os dados em treino e teste a partir do dataframe que foi realizado a feature engineering. Depois divido nas features preditoras(X_train) e o target(Y_train) e faço as previsões."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape treino: (20216100, 23) | Shape teste: (41697600, 22)\n"
     ]
    }
   ],
   "source": [
    "dftrain = dffe[:dftrain.shape[0]]\n",
    "dftest  = dffe[dftrain.shape[0]:].drop(['meter_reading'], axis=1)\n",
    "print('Shape treino: {:} | Shape teste: {:}'.format(dftrain.shape, dftest.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = dftrain.drop(['meter_reading'], axis = 1)\n",
    "y_train  = dftrain.meter_reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del dffe\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "                    'objective':'regression',\n",
    "                    'metric':'rmse',\n",
    "                    'n_jobs':-1,\n",
    "                    'learning_rate':0.05,\n",
    "                    'num_leaves': 40,\n",
    "                    'max_depth':-1,\n",
    "                    'subsample':0.85,\n",
    "                    'n_estimators':3000,\n",
    "                    'seed': SEED,\n",
    "                    'early_stopping_rounds':100,\n",
    "                } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[250]\ttraining's rmse: 0.851901\tvalid_1's rmse: 0.852512\n",
      "[500]\ttraining's rmse: 0.776566\tvalid_1's rmse: 0.778414\n",
      "[750]\ttraining's rmse: 0.736921\tvalid_1's rmse: 0.739843\n",
      "[1000]\ttraining's rmse: 0.704201\tvalid_1's rmse: 0.708086\n",
      "[1250]\ttraining's rmse: 0.68217\tvalid_1's rmse: 0.686925\n",
      "[1500]\ttraining's rmse: 0.663228\tvalid_1's rmse: 0.668874\n",
      "[1750]\ttraining's rmse: 0.647885\tvalid_1's rmse: 0.654386\n",
      "[2000]\ttraining's rmse: 0.636522\tvalid_1's rmse: 0.64377\n",
      "[2250]\ttraining's rmse: 0.62622\tvalid_1's rmse: 0.634212\n",
      "[2500]\ttraining's rmse: 0.617329\tvalid_1's rmse: 0.626081\n",
      "[2750]\ttraining's rmse: 0.608467\tvalid_1's rmse: 0.618096\n",
      "[3000]\ttraining's rmse: 0.601309\tvalid_1's rmse: 0.611685\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's rmse: 0.601309\tvalid_1's rmse: 0.611685\n",
      "Wall time: 38min 21s\n",
      "Wall time: 1h 3min 27s\n",
      "\n",
      "Fold: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[250]\ttraining's rmse: 0.856356\tvalid_1's rmse: 0.858295\n",
      "[500]\ttraining's rmse: 0.783825\tvalid_1's rmse: 0.7869\n",
      "[750]\ttraining's rmse: 0.743346\tvalid_1's rmse: 0.747455\n",
      "[1000]\ttraining's rmse: 0.713058\tvalid_1's rmse: 0.718066\n",
      "[1250]\ttraining's rmse: 0.689596\tvalid_1's rmse: 0.69572\n",
      "[1500]\ttraining's rmse: 0.671464\tvalid_1's rmse: 0.678519\n",
      "[1750]\ttraining's rmse: 0.652256\tvalid_1's rmse: 0.659952\n",
      "[2000]\ttraining's rmse: 0.639789\tvalid_1's rmse: 0.648173\n",
      "[2250]\ttraining's rmse: 0.629802\tvalid_1's rmse: 0.638872\n",
      "[2500]\ttraining's rmse: 0.619688\tvalid_1's rmse: 0.629372\n",
      "[2750]\ttraining's rmse: 0.60863\tvalid_1's rmse: 0.619135\n",
      "[3000]\ttraining's rmse: 0.599751\tvalid_1's rmse: 0.610958\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's rmse: 0.599751\tvalid_1's rmse: 0.610958\n",
      "Wall time: 38min 23s\n",
      "Wall time: 1h 5min 1s\n",
      "\n",
      "Fold: 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[250]\ttraining's rmse: 0.845826\tvalid_1's rmse: 0.84711\n",
      "[500]\ttraining's rmse: 0.781461\tvalid_1's rmse: 0.783987\n",
      "[750]\ttraining's rmse: 0.736987\tvalid_1's rmse: 0.740629\n",
      "[1000]\ttraining's rmse: 0.705298\tvalid_1's rmse: 0.710054\n",
      "[1250]\ttraining's rmse: 0.679767\tvalid_1's rmse: 0.685469\n",
      "[1500]\ttraining's rmse: 0.660152\tvalid_1's rmse: 0.666778\n",
      "[1750]\ttraining's rmse: 0.646164\tvalid_1's rmse: 0.653779\n",
      "[2000]\ttraining's rmse: 0.633881\tvalid_1's rmse: 0.642215\n",
      "[2250]\ttraining's rmse: 0.621718\tvalid_1's rmse: 0.631061\n",
      "[2500]\ttraining's rmse: 0.611619\tvalid_1's rmse: 0.62181\n",
      "[2750]\ttraining's rmse: 0.603074\tvalid_1's rmse: 0.613926\n",
      "[3000]\ttraining's rmse: 0.594856\tvalid_1's rmse: 0.606417\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's rmse: 0.594856\tvalid_1's rmse: 0.606417\n",
      "Wall time: 39min 21s\n",
      "Wall time: 1h 6min 16s\n",
      "\n",
      "Fold: 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[250]\ttraining's rmse: 0.851703\tvalid_1's rmse: 0.853528\n",
      "[500]\ttraining's rmse: 0.782449\tvalid_1's rmse: 0.785382\n",
      "[750]\ttraining's rmse: 0.741347\tvalid_1's rmse: 0.745443\n",
      "[1000]\ttraining's rmse: 0.710932\tvalid_1's rmse: 0.716036\n",
      "[1250]\ttraining's rmse: 0.68869\tvalid_1's rmse: 0.694687\n",
      "[1500]\ttraining's rmse: 0.666727\tvalid_1's rmse: 0.673767\n",
      "[1750]\ttraining's rmse: 0.649869\tvalid_1's rmse: 0.657988\n",
      "[2000]\ttraining's rmse: 0.638168\tvalid_1's rmse: 0.64706\n",
      "[2250]\ttraining's rmse: 0.625674\tvalid_1's rmse: 0.635408\n",
      "[2500]\ttraining's rmse: 0.615843\tvalid_1's rmse: 0.626352\n",
      "[2750]\ttraining's rmse: 0.606618\tvalid_1's rmse: 0.617763\n",
      "[3000]\ttraining's rmse: 0.598577\tvalid_1's rmse: 0.610377\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's rmse: 0.598577\tvalid_1's rmse: 0.610377\n",
      "Wall time: 38min 43s\n",
      "Wall time: 1h 2min 17s\n",
      "\n",
      "Fold: 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[250]\ttraining's rmse: 0.847013\tvalid_1's rmse: 0.847878\n",
      "[500]\ttraining's rmse: 0.777669\tvalid_1's rmse: 0.779992\n",
      "[750]\ttraining's rmse: 0.741043\tvalid_1's rmse: 0.744434\n",
      "[1000]\ttraining's rmse: 0.714025\tvalid_1's rmse: 0.718447\n",
      "[1250]\ttraining's rmse: 0.691041\tvalid_1's rmse: 0.696328\n",
      "[1500]\ttraining's rmse: 0.670189\tvalid_1's rmse: 0.676281\n",
      "[1750]\ttraining's rmse: 0.652991\tvalid_1's rmse: 0.659941\n",
      "[2000]\ttraining's rmse: 0.639759\tvalid_1's rmse: 0.64763\n",
      "[2250]\ttraining's rmse: 0.62759\tvalid_1's rmse: 0.636441\n",
      "[2500]\ttraining's rmse: 0.618176\tvalid_1's rmse: 0.627719\n",
      "[2750]\ttraining's rmse: 0.609918\tvalid_1's rmse: 0.620141\n",
      "[3000]\ttraining's rmse: 0.600917\tvalid_1's rmse: 0.611938\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's rmse: 0.600917\tvalid_1's rmse: 0.611938\n",
      "Wall time: 38min 8s\n",
      "Wall time: 1h 1min 14s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "K = 5\n",
    "folds = KFold(K, shuffle=True, random_state = SEED)\n",
    "finalpred = np.zeros(dftest.shape[0])\n",
    "for fold , (train_index,test_index) in enumerate(folds.split(X_train, y_train)):\n",
    "    print('Fold:',fold+1)\n",
    "          \n",
    "    X_traincv, X_testcv = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    y_traincv, y_testcv = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    \n",
    "    train_data = lgb.Dataset(X_traincv, y_traincv)\n",
    "    val_data   = lgb.Dataset(X_testcv, y_testcv)\n",
    "    \n",
    "    %time LGBM = lgb.train(lgb_params, train_data, valid_sets= [train_data,val_data], verbose_eval=250)\n",
    "    %time finalpred += np.expm1(LGBM.predict(dftest))\n",
    "    print()\n",
    "    \n",
    "finalpred /= K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As previsões são a média do exponencial (para transformar de volta na escala original) da previsão de cada fold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leio o arquivo de submissão da competição com os id's das linhas, e adiciono as minhas previsões. Salvo o arquivo em formato comprimido para economizar espaço no disco e para o upload no site do Kaggle ser mais rápido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>33.650735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.133963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5.319478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17.110090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>61.721774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  meter_reading\n",
       "0       0      33.650735\n",
       "1       1      20.133963\n",
       "2       2       5.319478\n",
       "3       3      17.110090\n",
       "4       4      61.721774"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission['meter_reading'] = finalpred\n",
    "submission['meter_reading'] = np.where((submission['meter_reading'] < 0), 0, submission['meter_reading'])\n",
    "submission.to_csv('solution.csv.gz',index=False,compression='gzip')\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atualmente esta solução tem uma RMSLE de 1.14 no leaderboard do Kaggle e está entre as melhores 29%. A melhor solução publicada até o momento tem um RMSLE de 1.05."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
